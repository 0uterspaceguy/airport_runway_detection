# ЛЦТ 2024. Сервис детекции посторонних объектов на взлетно-посадочных полосах. 

## Как это работает

Для детекции используется нейросеть [Yolov10](https://github.com/THU-MIG/yolov10/tree/main)

Обученная нейросеть запускается в пайплайне [DeepStream](https://developer.nvidia.com/deepstream-sdk)

При первом запуске приложения будет сгенерирован TensorRT engine. 
Это может занять минут 10, но необходимо только один раз на одной машине.

Для поиска объектов на изображениях используется pytorch модель. Очень уж неудобно обрабатывать датасет изображений в пайплайне DeepStream. А python обертка для TensorRT сильно замедляет процесс. Если потребуется, можно самостоятельно воспользоваться скриптом "infer_images.py"

Для обработки видео используется "entrypoint_video.sh".
Этот скрипт запускает пайплайн DeepStream. Учитывайте что на запуск пайплайна обычно уходит несколько секунд.
Поэтому если запускать короткие видео, то может показаться что обработка слишком долгая.

Для веб приложения используется flet. Стоит воспринимать это как простую демонстрацию. Конечно, если забыть про подсчет метрик и визуальную оценку, стоит пользоваться этой нейросетью безо всяких надстроек и оберток. Просто в пайплайне DeepStream.

Если у вас будет желание, можно самостоятельно запустить "entrypoint_video.sh" внутри контейнера.
По правде говоря, достаточно много времени съедают загрузка и сохранение видео. 

## Запуск

Все что вам нужно - это запустить docker compose

```
sudo docker compose up -d
```

И перейти по ссылке http://0.0.0.0:57777

По необходимости вы можете изменить пути в docker-compose.yaml

```yaml
...
    volumes:
      - ./models:/workspace/models  # Папка с моделями
      - ./results:/workspace/results  # Папка с результатами
...

```
Не меняйте пожалуйста пути внутри контейнера.

## Как пользоваться приложением

### Изображения

Во вкладке с изображениями мы можете загрузить одно или несколько изображений, можно хоть целый датасет.

После обработки можно отдельно скачать отрисовку, аннотации и посмотреть на картинки в самом приложении.

Вобщем все кнопки подписаны, не думаю что тут возникнут проблемы.



### Видео

Видео можно загружать только по одному. Также по окончании обработки можно посмотреть отрисовку в приложении или скачать результаты.

Полоска под видео показывает наличие опасных (красным цветом) и безопасных (зеленым цветом) объектов в видео. 
Можно перематывать видео в соответствии с этим индикатором.


## Результаты

Все результаты сохраняются по пути, который вы указали в docker-compose.yaml. Все изображения, аннотации, видео и логи к видео.

